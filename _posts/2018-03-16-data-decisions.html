---
layout: post
title: Data Decisions
date: 2018-03-16 16:45:36.000000000 -04:00
type: post
parent_id: '0'
published: true
password: ''
status: publish
categories: []
tags: []
meta:
  _rest_api_published: '1'
  timeline_notification: '1521468646'
  _rest_api_client_id: "-1"
  _publicize_job_id: '15884524061'
author:
  login: bmrgoldman
  email: bmrgoldman@gmail.com
  display_name: Ben Goldman
  first_name: Ben
  last_name: Goldman
permalink: "/2018/03/16/data-decisions/"
---
<p>Like many archivists, I have experienced the frustrations and satisfactions that attend the process of moving your institution's archival data from one system to another, which typically demands a reckoning with past descriptive practices (no judgment; practices evolve) and a better understanding of modern encoding and descriptive standards. My participation in such efforts has given me a deep respect for archivists who understands the ins and outs of these descriptive frameworks and encoding standards.</p>
<p>Alas, I am not one of those archivists (**please keep this in mind as I try my best to explain below our understanding of archival data approaches). So in planning our grant, we spent some time consulting with standards documents and peer experts to ensure that the final dataset models repository locations data in a way that supports maintenance, reuse, and portability to other descriptive frameworks.</p>
<p>Current archival descriptive practice seems somewhat inconclusive (or unemphatic, perhaps?) when it comes to encoding repository information. <a href="https://github.com/saa-ts-dacs/dacs/blob/master/part_I/chapter_2/2_name_and_location_of_repository.md" target="_blank" rel="noopener">Describing Archives: A Content Standard (DACS) guidelines for encoding repository information are fairly remedial</a> (see 2.2), suggesting only that an address and contact information may be "desirable". Section 5 of the <a href="https://www.ica.org/sites/default/files/CBPS_2008_Guidelines_ISDIAH_First-edition_EN.pdf" target="_blank" rel="noopener">International Standard for Describing Institutions with Archival Holdings (ISDIAH)</a> provides considerable guidance on describing a repository's name, parent institution, identifier, location, services, and mission. One noteworthy area of that section is 5.6 (Control Area), which suggests identifying the <em>sources of your data and the dates of creation or revision </em>(thanks to Mike Rush for pointing this out to us)<em>. </em>ISDIAH, we learned, is now (or soon to be) considered superseded by the International Council on Archives' <a href="https://www.ica.org/sites/default/files/RiC-CM-0.1.pdf" target="_blank" rel="noopener">Records in Context (RiC)</a>, which treats repositories as Agents (corporate bodies). Aspects of ISDIAH have seemingly been translated to RiC's section 3, Properties of Entities -- specifically, 3.1 (for names and identifiers), 3.7 (for types of agents), 3.10 (for contact information) and 3.19 ("Properties of Place", which includes location information and even geographic coordinates.</p>
<p>For a real life example of how all this might translate to an Agent record in Encoded Archival Context (EAC), see below (thanks to Robbie Hott, who helpfully shared some data samples from the Social Networks and Archival Context (SNAC) project):</p>
<p><img class="alignnone size-full wp-image-136" src="{{ site.baseurl }}/assets/screen-shot-2018-03-16-at-12-06-04-pm.png" alt="Screen Shot 2018-03-16 at 12.06.04 PM" width="950" height="440" /></p>
<p>Something not really addressed in these examples is the type of archival repository. <a href="https://repositorydata.wordpress.com/2017/11/27/what-is-an-archive/">As we've discussed</a>, definitions of "archive" are hard to pin down, but it's something we've been trying to give attention to as we work through the data.</p>
<p>Building on these descriptive approaches, we initially wanted to establish the following data on all repositories:</p>
<ul>
<li>Repository Name</li>
<li>Parent Institution Name</li>
<li>Authorized Name</li>
<li>Authorized Name Source</li>
<li>Repository Identifier</li>
<li>Repository Identifier Source</li>
<li>Location Type (e.g. Mailing Address, Street Address)</li>
<li>Street Address 1</li>
<li>Street Address 2</li>
<li>City</li>
<li>State/Province</li>
<li>Zip Code</li>
<li>Country</li>
<li>Longitude</li>
<li>Latitude</li>
<li>Data Source</li>
<li>Date of Entry</li>
<li>Name of Person Recording the Entry</li>
</ul>
<p>We quickly realized that separately gathering authorized names and identifiers from a source like the <a href="https://www.loc.gov/marc/organizations/" target="_blank" rel="noopener">Library of Congress's MARC organization codes</a> would be too labor intensive. Longitude and latitude are absolutely critical pieces of data, but not something that was likely to be included in existing datasets. Instead of gathering that data now, our plan is auto-generate the geocoordinates using a service like <a href="https://geocod.io/" target="_blank" rel="noopener">Geocodio</a> at the end of our project. We were also surprised (though probably should not have been) to discover that some data sources included both a mailing and street address for some repositories. In these cases, we have created two separate entries for the same repository, and created a new field in our data for "location type" to distinguish separate entries for the same repository.</p>
<p>(Geocodio itself provides some interesting data considerations, including the concept of <em>accuracy</em>. For instance, it still generate coordinates for P.O. boxes, <a href="https://www.loc.gov/marc/organizations/" target="_blank" rel="noopener">but encodes that location as a <em>place</em> rather than a <em>point</em></a>, and then provides an accuracy score. Geocodio also auto-generates county names, and normalizes address information, which will also come in handy for our project.)</p>
<p>In the end, our final dataset should bring together the name and location elements we've described here, aggregated into a single CSV file, which should lend itself to being migrated to other formats and integrated into other systems as needed. We'll also make the final data accessible through an Open Science Framework or Github repository so that others can continue the work we've begun. Other data sources will come to light, or repositories themselves may potentially find errors in our data that require updating. Ongoing maintenance will be required, which is why we hope this data can be stewarded by SAA once we're done. Regardless of the ultimate disposition, this should be data the community of archival professionals and related stakeholders can make use of in the future.</p>
